{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alice/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ROCStories_winter2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>storytitle</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>sentence5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd</td>\n",
       "      <td>David Drops the Weight</td>\n",
       "      <td>David noticed he had put on a lot of weight re...</td>\n",
       "      <td>He examined his habits to try and figure out t...</td>\n",
       "      <td>He realized he'd been eating too much fast foo...</td>\n",
       "      <td>He stopped going to burger places and started ...</td>\n",
       "      <td>After a few weeks, he started to feel much bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0beabab2-fb49-460e-a6e6-f35a202e3348</td>\n",
       "      <td>Frustration</td>\n",
       "      <td>Tom had a very short temper.</td>\n",
       "      <td>One day a guest made him very angry.</td>\n",
       "      <td>He punched a hole in the wall of his house.</td>\n",
       "      <td>Tom's guest became afraid and left quickly.</td>\n",
       "      <td>Tom sat on his couch filled with regret about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87da1a22-df0b-410c-b186-439700b70ba6</td>\n",
       "      <td>Marcus Buys Khakis</td>\n",
       "      <td>Marcus needed clothing for a business casual e...</td>\n",
       "      <td>All of his clothes were either too formal or t...</td>\n",
       "      <td>He decided to buy a pair of khakis.</td>\n",
       "      <td>The pair he bought fit him perfectly.</td>\n",
       "      <td>Marcus was happy to have the right clothes for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9</td>\n",
       "      <td>Different Opinions</td>\n",
       "      <td>Bobby thought Bill should buy a trailer and ha...</td>\n",
       "      <td>Bill thought a truck would be better for what ...</td>\n",
       "      <td>Bobby pointed out two vehicles were much more ...</td>\n",
       "      <td>Bill was set in his ways with conventional thi...</td>\n",
       "      <td>He ended up buying the truck he wanted despite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c71bb23b-7731-4233-8298-76ba6886cee1</td>\n",
       "      <td>Overcoming shortcomings</td>\n",
       "      <td>John was a pastor with a very bad memory.</td>\n",
       "      <td>He tried to memorize his sermons many days in ...</td>\n",
       "      <td>He decided to learn to sing to overcome his ha...</td>\n",
       "      <td>He then made all his sermons into music and sa...</td>\n",
       "      <td>His congregation was delighted and so was he.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                storyid               storytitle  \\\n",
       "0  8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd   David Drops the Weight   \n",
       "1  0beabab2-fb49-460e-a6e6-f35a202e3348              Frustration   \n",
       "2  87da1a22-df0b-410c-b186-439700b70ba6       Marcus Buys Khakis   \n",
       "3  2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9       Different Opinions   \n",
       "4  c71bb23b-7731-4233-8298-76ba6886cee1  Overcoming shortcomings   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  David noticed he had put on a lot of weight re...   \n",
       "1                       Tom had a very short temper.   \n",
       "2  Marcus needed clothing for a business casual e...   \n",
       "3  Bobby thought Bill should buy a trailer and ha...   \n",
       "4          John was a pastor with a very bad memory.   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  He examined his habits to try and figure out t...   \n",
       "1               One day a guest made him very angry.   \n",
       "2  All of his clothes were either too formal or t...   \n",
       "3  Bill thought a truck would be better for what ...   \n",
       "4  He tried to memorize his sermons many days in ...   \n",
       "\n",
       "                                           sentence3  \\\n",
       "0  He realized he'd been eating too much fast foo...   \n",
       "1        He punched a hole in the wall of his house.   \n",
       "2                He decided to buy a pair of khakis.   \n",
       "3  Bobby pointed out two vehicles were much more ...   \n",
       "4  He decided to learn to sing to overcome his ha...   \n",
       "\n",
       "                                           sentence4  \\\n",
       "0  He stopped going to burger places and started ...   \n",
       "1        Tom's guest became afraid and left quickly.   \n",
       "2              The pair he bought fit him perfectly.   \n",
       "3  Bill was set in his ways with conventional thi...   \n",
       "4  He then made all his sermons into music and sa...   \n",
       "\n",
       "                                           sentence5  \n",
       "0  After a few weeks, he started to feel much bet...  \n",
       "1  Tom sat on his couch filled with regret about ...  \n",
       "2  Marcus was happy to have the right clothes for...  \n",
       "3  He ended up buying the truck he wanted despite...  \n",
       "4      His congregation was delighted and so was he.  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David noticed he had put on a lot of weight recently.\n",
      "Tom had a very short temper.\n",
      "Marcus needed clothing for a business casual event.\n",
      "Bobby thought Bill should buy a trailer and haul it with his car.\n",
      "John was a pastor with a very bad memory.\n",
      "Melody's parents surprised her with a trip to the big aquarium.\n",
      "The math teacher announced a pop quiz as class began.\n",
      "My first girlfriend i met on the internet.\n",
      "I got Charlie Horse when I was four years old.\n",
      "Laura loved corn.\n",
      "Andy was invited to a Halloween party.\n",
      "Luke was playing hockey at school.\n",
      "Robbie was competing in a cross country meet.\n",
      "Jude was very excited about his college graduation ceremony.\n",
      "Beth sent a letter to Santa Claus.\n",
      "Our granddaughter Anna is very fussy about her clothes.\n",
      "Jake needed a ride to the store.\n",
      "I'd been looking for a stand for my TV.\n",
      "Sally had a root canal this morning, as she had a damaged root.\n",
      "My dog is terrified of thunder.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(df.sentence1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He examined his habits to try and figure out the reason.\n",
      "One day a guest made him very angry.\n",
      "All of his clothes were either too formal or too casual.\n",
      "Bill thought a truck would be better for what he needed.\n",
      "He tried to memorize his sermons many days in advance but to no avail.\n",
      "Melody took a nap during the two hour car ride to the aquarium.\n",
      "While some students complained, he began passing out the quiz.\n",
      "She lives about 4 hours away from me.\n",
      "He's a brown stuffed horse, and at 35 I still sleep with him at night.\n",
      "So she decided to grow some in her backyard.\n",
      "Andy figured that for dramatic effect, he should color his hair.\n",
      "The game was tied and almost over.\n",
      "He was halfway through when his leg cramped up.\n",
      "On the way to the arena, he got stuck in traffic.\n",
      "She received a letter back in the mail.\n",
      "She is only two, but wants to pick her outfits.\n",
      "His girlfriend was working and wouldn't take him.\n",
      "I looked everywhere, but the ones I saw were expensive.\n",
      "After the procedure, the dentist wrote her a prescription.\n",
      "There was a storm today.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(df.sentence2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens_1 = word_tokenize(\" \".join(df.sentence1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52665"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"sentence1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(df):\n",
    "    tokens = []\n",
    "    columns = [\"sentence1\", \"sentence2\", \"sentence3\", \"sentence4\", \"sentence5\"]\n",
    "    for col in columns:\n",
    "        tok_col = word_tokenize(\" \".join(df[col]))\n",
    "        tokens += tok_col\n",
    "    unique_tokens = list(set(tokens))\n",
    "    return tokens, unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens, unique_tokens = build_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32296"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_tokens_1 = list(set(tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16396"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tokens_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {k:v for k,v in enumerate(unique_tokens_1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vocab_ROC_sentence1.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentences(df, max_samples=20000):\n",
    "    sentences = df.sentence1[:max_samples]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(sentences):\n",
    "    tokenize_func=lambda t : word_tokenize(t.lower())\n",
    "    #tokens = word_tokenize(' '.join(sentences))\n",
    "    tokenized_sentences = sentences.apply(tokenize_func)\n",
    "    tokenized_sentences = tokenized_sentences.values\n",
    "    tokens = [w for s in tokenized_sentences for w in s]\n",
    "    unique_tokens = list(set(tokens))\n",
    "    vocab = {v:k for k,v in enumerate(unique_tokens)}\n",
    "    return tokens, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train_test(sentences, train_size=10000, val_size=5000, test_size=5000):\n",
    "    train_sentences = sentences[:train_size]\n",
    "    val_sentences = sentences[train_size:train_size+val_size]\n",
    "    test_sentences = sentences[train_size+val_size:train_size+val_size+test_size]\n",
    "    train_data = split_dataset_elements(train_sentences)\n",
    "    val_data = split_dataset_elements(val_sentences)\n",
    "    test_data = split_dataset_elements(test_sentences)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences, vocab):\n",
    "    tokenize_func=lambda t : word_tokenize(t.lower())\n",
    "    tok_to_id_func = lambda t: [vocab[w] for w in t]\n",
    "    tokenized_sentences = sentences.apply(tokenize_func)\n",
    "    tokens_id = tokenized_sentences.apply(tok_to_id_func)\n",
    "    #TODO: split between input and target sentence. \n",
    "    df = pd.DataFrame()\n",
    "    df[\"input_sentence\"] = tokens_id.apply(lambda t: t[:-1])\n",
    "    df[\"target_sentence\"] = tokens_id.apply(lambda t: t[1:])\n",
    "    len_sentences = tokens_id.apply(len)\n",
    "    max_len = len_sentences.max() - 1\n",
    "    df[\"attention_mask\"] = len_sentences.apply(lambda t: [1]*(t-1) + [0]*(max_len - (t-1)))\n",
    "    print(\"max len\", max_len)\n",
    "    pad_func = lambda t: t + [0]*(max_len-len(t))\n",
    "    padded_token_ids = df.apply(pad_func)\n",
    "    return padded_token_ids, len_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset_elements(dataset):\n",
    "    input_sentence = dataset.input_sentence\n",
    "    target_sentence = dataset.target_sentence\n",
    "    attention_mask = dataset.attention_mask\n",
    "    return input_sentence, target_sentence, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = get_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens, vocab = get_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 18\n"
     ]
    }
   ],
   "source": [
    "dataset, len_sentences = tokenize(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_train, target_train, _ = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([9167, 8594, 8287, 4020, 5094, 5664, 9050, 1210, 299, 7885, 37]),\n",
       "       list([1793, 4020, 9050, 5612, 3883, 80]),\n",
       "       list([9335, 3956, 6190, 278, 9050, 8115, 9016, 4629]), ...,\n",
       "       list([7180, 5086, 9050, 775, 9294, 988, 4195, 9532, 5249, 4565]),\n",
       "       list([1509, 8086, 5555, 2867, 3286, 8540, 1412, 6725, 3962, 1672]),\n",
       "       list([1793, 5086, 874, 5555, 9050, 8614, 2999])], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_id.attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9627"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 60000 into shape (20000,18,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-498ef3ddace7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtokens_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/alice/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alice/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 60000 into shape (20000,18,3)"
     ]
    }
   ],
   "source": [
    "data =tokens_id.values\n",
    "data_b = np.reshape(data, newshape=(data.shape[0], 18, data.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9167, 8594, 8287, 4020, 5094, 5664, 9050, 1210, 299, 7885, 37]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.zeros(data.shape[0], 18, data.shape[-1])\n",
    "for ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
